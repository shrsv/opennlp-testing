


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: TokenizerME</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">opennlp.tools.tokenize</a> ]
</div>

<h1>Coverage Summary for Class: TokenizerME (opennlp.tools.tokenize)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">TokenizerME</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    62.5%
  </span>
  <span class="absValue">
    (5/ 8)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    70.8%
  </span>
  <span class="absValue">
    (46/ 65)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License. You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *     http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package opennlp.tools.tokenize;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.io.IOException;
<i>21</i>&nbsp;import java.util.ArrayList;
<i>22</i>&nbsp;import java.util.Collections;
<i>23</i>&nbsp;import java.util.HashMap;
<i>24</i>&nbsp;import java.util.List;
<i>25</i>&nbsp;import java.util.Map;
<i>26</i>&nbsp;import java.util.Set;
<i>27</i>&nbsp;import java.util.regex.Pattern;
<i>28</i>&nbsp;
<i>29</i>&nbsp;import opennlp.tools.dictionary.Dictionary;
<i>30</i>&nbsp;import opennlp.tools.ml.EventTrainer;
<i>31</i>&nbsp;import opennlp.tools.ml.TrainerFactory;
<i>32</i>&nbsp;import opennlp.tools.ml.model.Event;
<i>33</i>&nbsp;import opennlp.tools.ml.model.MaxentModel;
<i>34</i>&nbsp;import opennlp.tools.tokenize.lang.Factory;
<i>35</i>&nbsp;import opennlp.tools.util.ObjectStream;
<i>36</i>&nbsp;import opennlp.tools.util.Span;
<i>37</i>&nbsp;import opennlp.tools.util.TrainingParameters;
<i>38</i>&nbsp;
<i>39</i>&nbsp;/**
<i>40</i>&nbsp; * A Tokenizer for converting raw text into separated tokens.  It uses
<i>41</i>&nbsp; * Maximum Entropy to make its decisions.  The features are loosely
<i>42</i>&nbsp; * based off of Jeff Reynar&#39;s UPenn thesis &quot;Topic Segmentation:
<i>43</i>&nbsp; * Algorithms and Applications.&quot;, which is available from his
<i>44</i>&nbsp; * homepage: &lt;a href=&quot;http://www.cis.upenn.edu/~jcreynar&quot;&gt;http://www.cis.upenn.edu/~jcreynar&lt;/a&gt;.
<i>45</i>&nbsp; * &lt;p&gt;
<i>46</i>&nbsp; * This tokenizer needs a statistical model to tokenize a text which reproduces
<i>47</i>&nbsp; * the tokenization observed in the training data used to create the model.
<i>48</i>&nbsp; * The {@link TokenizerModel} class encapsulates the model and provides
<i>49</i>&nbsp; * methods to create it from the binary representation.
<i>50</i>&nbsp; * &lt;p&gt;
<i>51</i>&nbsp; * A tokenizer instance is not thread safe. For each thread one tokenizer
<i>52</i>&nbsp; * must be instantiated which can share one &lt;code&gt;TokenizerModel&lt;/code&gt; instance
<i>53</i>&nbsp; * to safe memory.
<i>54</i>&nbsp; * &lt;p&gt;
<i>55</i>&nbsp; * To train a new model {{@link #train(ObjectStream, TokenizerFactory, TrainingParameters)} method
<i>56</i>&nbsp; * can be used.
<i>57</i>&nbsp; * &lt;p&gt;
<i>58</i>&nbsp; * Sample usage:
<i>59</i>&nbsp; * &lt;p&gt;
<i>60</i>&nbsp; * &lt;code&gt;
<i>61</i>&nbsp; * InputStream modelIn;&lt;br&gt;
<i>62</i>&nbsp; * &lt;br&gt;
<i>63</i>&nbsp; * ...&lt;br&gt;
<i>64</i>&nbsp; * &lt;br&gt;
<i>65</i>&nbsp; * TokenizerModel model = TokenizerModel(modelIn);&lt;br&gt;
<i>66</i>&nbsp; * &lt;br&gt;
<i>67</i>&nbsp; * Tokenizer tokenizer = new TokenizerME(model);&lt;br&gt;
<i>68</i>&nbsp; * &lt;br&gt;
<i>69</i>&nbsp; * String tokens[] = tokenizer.tokenize(&quot;A sentence to be tokenized.&quot;);
<i>70</i>&nbsp; * &lt;/code&gt;
<i>71</i>&nbsp; *
<i>72</i>&nbsp; * @see Tokenizer
<i>73</i>&nbsp; * @see TokenizerModel
<i>74</i>&nbsp; * @see TokenSample
<i>75</i>&nbsp; */
<i>76</i>&nbsp;public class TokenizerME extends AbstractTokenizer {
<i>77</i>&nbsp;
<i>78</i>&nbsp;  /**
<i>79</i>&nbsp;   * Constant indicates a token split.
<i>80</i>&nbsp;   */
<i>81</i>&nbsp;  public static final String SPLIT = &quot;T&quot;;
<i>82</i>&nbsp;
<i>83</i>&nbsp;  /**
<i>84</i>&nbsp;   * Constant indicates no token split.
<i>85</i>&nbsp;   */
<i>86</i>&nbsp;  public static final String NO_SPLIT = &quot;F&quot;;
<i>87</i>&nbsp;
<i>88</i>&nbsp;  /**
<i>89</i>&nbsp;   * Alpha-Numeric Pattern
<i>90</i>&nbsp;   * @deprecated As of release 1.5.2, replaced by {@link Factory#getAlphanumeric(String)}
<i>91</i>&nbsp;   */
<i>92</i>&nbsp;  @Deprecated
<b class="fc"><i>93</i>&nbsp;  public static final Pattern alphaNumeric = Pattern.compile(Factory.DEFAULT_ALPHANUMERIC);</b>
<i>94</i>&nbsp;
<i>95</i>&nbsp;  private final Pattern alphanumeric;
<i>96</i>&nbsp;
<i>97</i>&nbsp;  /**
<i>98</i>&nbsp;   * The maximum entropy model to use to evaluate contexts.
<i>99</i>&nbsp;   */
<i>100</i>&nbsp;  private MaxentModel model;
<i>101</i>&nbsp;
<i>102</i>&nbsp;  /**
<i>103</i>&nbsp;   * The context generator.
<i>104</i>&nbsp;   */
<i>105</i>&nbsp;  private final TokenContextGenerator cg;
<i>106</i>&nbsp;
<i>107</i>&nbsp;  /**
<i>108</i>&nbsp;   * Optimization flag to skip alpha numeric tokens for further
<i>109</i>&nbsp;   * tokenization
<i>110</i>&nbsp;   */
<i>111</i>&nbsp;  private boolean useAlphaNumericOptimization;
<i>112</i>&nbsp;
<i>113</i>&nbsp;  /**
<i>114</i>&nbsp;   * List of probabilities for each token returned from a call to
<i>115</i>&nbsp;   * &lt;code&gt;tokenize&lt;/code&gt; or &lt;code&gt;tokenizePos&lt;/code&gt;.
<i>116</i>&nbsp;   */
<i>117</i>&nbsp;  private List&lt;Double&gt; tokProbs;
<i>118</i>&nbsp;
<i>119</i>&nbsp;  private List&lt;Span&gt; newTokens;
<i>120</i>&nbsp;
<b class="fc"><i>121</i>&nbsp;  public TokenizerME(TokenizerModel model) {</b>
<b class="fc"><i>122</i>&nbsp;    TokenizerFactory factory = model.getFactory();</b>
<b class="fc"><i>123</i>&nbsp;    this.alphanumeric = factory.getAlphaNumericPattern();</b>
<b class="fc"><i>124</i>&nbsp;    this.cg = factory.getContextGenerator();</b>
<b class="fc"><i>125</i>&nbsp;    this.model = model.getMaxentModel();</b>
<b class="fc"><i>126</i>&nbsp;    this.useAlphaNumericOptimization = factory.isUseAlphaNumericOptmization();</b>
<i>127</i>&nbsp;
<b class="fc"><i>128</i>&nbsp;    newTokens = new ArrayList&lt;&gt;();</b>
<b class="fc"><i>129</i>&nbsp;    tokProbs = new ArrayList&lt;&gt;(50);</b>
<b class="fc"><i>130</i>&nbsp;  }</b>
<i>131</i>&nbsp;
<i>132</i>&nbsp;  /**
<i>133</i>&nbsp;   * @deprecated use {@link TokenizerFactory} to extend the Tokenizer
<i>134</i>&nbsp;   *             functionality
<i>135</i>&nbsp;   */
<b class="nc"><i>136</i>&nbsp;  public TokenizerME(TokenizerModel model, Factory factory) {</b>
<b class="nc"><i>137</i>&nbsp;    String languageCode = model.getLanguage();</b>
<i>138</i>&nbsp;
<b class="nc"><i>139</i>&nbsp;    this.alphanumeric = factory.getAlphanumeric(languageCode);</b>
<b class="nc"><i>140</i>&nbsp;    this.cg = factory.createTokenContextGenerator(languageCode,</b>
<b class="nc"><i>141</i>&nbsp;        getAbbreviations(model.getAbbreviations()));</b>
<i>142</i>&nbsp;
<b class="nc"><i>143</i>&nbsp;    this.model = model.getMaxentModel();</b>
<b class="nc"><i>144</i>&nbsp;    useAlphaNumericOptimization = model.useAlphaNumericOptimization();</b>
<i>145</i>&nbsp;
<b class="nc"><i>146</i>&nbsp;    newTokens = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>147</i>&nbsp;    tokProbs = new ArrayList&lt;&gt;(50);</b>
<b class="nc"><i>148</i>&nbsp;  }</b>
<i>149</i>&nbsp;
<i>150</i>&nbsp;  private static Set&lt;String&gt; getAbbreviations(Dictionary abbreviations) {
<b class="nc"><i>151</i>&nbsp;    if (abbreviations == null) {</b>
<b class="nc"><i>152</i>&nbsp;      return Collections.emptySet();</b>
<i>153</i>&nbsp;    }
<b class="nc"><i>154</i>&nbsp;    return abbreviations.asStringSet();</b>
<i>155</i>&nbsp;  }
<i>156</i>&nbsp;
<i>157</i>&nbsp;  /**
<i>158</i>&nbsp;   * Returns the probabilities associated with the most recent
<i>159</i>&nbsp;   * calls to {@link TokenizerME#tokenize(String)} or {@link TokenizerME#tokenizePos(String)}.
<i>160</i>&nbsp;   *
<i>161</i>&nbsp;   * @return probability for each token returned for the most recent
<i>162</i>&nbsp;   *     call to tokenize.  If not applicable an empty array is returned.
<i>163</i>&nbsp;   */
<i>164</i>&nbsp;  public double[] getTokenProbabilities() {
<b class="nc"><i>165</i>&nbsp;    double[] tokProbArray = new double[tokProbs.size()];</b>
<b class="nc"><i>166</i>&nbsp;    for (int i = 0; i &lt; tokProbArray.length; i++) {</b>
<b class="nc"><i>167</i>&nbsp;      tokProbArray[i] = tokProbs.get(i);</b>
<i>168</i>&nbsp;    }
<b class="nc"><i>169</i>&nbsp;    return tokProbArray;</b>
<i>170</i>&nbsp;  }
<i>171</i>&nbsp;
<i>172</i>&nbsp;  /**
<i>173</i>&nbsp;   * Tokenizes the string.
<i>174</i>&nbsp;   *
<i>175</i>&nbsp;   * @param d  The string to be tokenized.
<i>176</i>&nbsp;   *
<i>177</i>&nbsp;   * @return   A span array containing individual tokens as elements.
<i>178</i>&nbsp;   */
<i>179</i>&nbsp;  public Span[] tokenizePos(String d) {
<b class="fc"><i>180</i>&nbsp;    Span[] tokens = WhitespaceTokenizer.INSTANCE.tokenizePos(d);</b>
<b class="fc"><i>181</i>&nbsp;    newTokens.clear();</b>
<b class="fc"><i>182</i>&nbsp;    tokProbs.clear();</b>
<b class="fc"><i>183</i>&nbsp;    for (Span s : tokens) {</b>
<b class="fc"><i>184</i>&nbsp;      String tok = d.substring(s.getStart(), s.getEnd());</b>
<i>185</i>&nbsp;      // Can&#39;t tokenize single characters
<b class="fc"><i>186</i>&nbsp;      if (tok.length() &lt; 2) {</b>
<b class="nc"><i>187</i>&nbsp;        newTokens.add(s);</b>
<b class="nc"><i>188</i>&nbsp;        tokProbs.add(1d);</b>
<b class="fc"><i>189</i>&nbsp;      } else if (useAlphaNumericOptimization() &amp;&amp; alphanumeric.matcher(tok).matches()) {</b>
<b class="fc"><i>190</i>&nbsp;        newTokens.add(s);</b>
<b class="fc"><i>191</i>&nbsp;        tokProbs.add(1d);</b>
<i>192</i>&nbsp;      } else {
<b class="fc"><i>193</i>&nbsp;        int start = s.getStart();</b>
<b class="fc"><i>194</i>&nbsp;        int end = s.getEnd();</b>
<b class="fc"><i>195</i>&nbsp;        final int origStart = s.getStart();</b>
<b class="fc"><i>196</i>&nbsp;        double tokenProb = 1.0;</b>
<b class="fc"><i>197</i>&nbsp;        for (int j = origStart + 1; j &lt; end; j++) {</b>
<b class="fc"><i>198</i>&nbsp;          double[] probs =</b>
<b class="fc"><i>199</i>&nbsp;              model.eval(cg.getContext(tok, j - origStart));</b>
<b class="fc"><i>200</i>&nbsp;          String best = model.getBestOutcome(probs);</b>
<b class="fc"><i>201</i>&nbsp;          tokenProb *= probs[model.getIndex(best)];</b>
<b class="fc"><i>202</i>&nbsp;          if (best.equals(TokenizerME.SPLIT)) {</b>
<b class="fc"><i>203</i>&nbsp;            newTokens.add(new Span(start, j));</b>
<b class="fc"><i>204</i>&nbsp;            tokProbs.add(tokenProb);</b>
<b class="fc"><i>205</i>&nbsp;            start = j;</b>
<b class="fc"><i>206</i>&nbsp;            tokenProb = 1.0;</b>
<i>207</i>&nbsp;          }
<i>208</i>&nbsp;        }
<b class="fc"><i>209</i>&nbsp;        newTokens.add(new Span(start, end));</b>
<b class="fc"><i>210</i>&nbsp;        tokProbs.add(tokenProb);</b>
<i>211</i>&nbsp;      }
<i>212</i>&nbsp;    }
<i>213</i>&nbsp;
<b class="fc"><i>214</i>&nbsp;    Span[] spans = new Span[newTokens.size()];</b>
<b class="fc"><i>215</i>&nbsp;    newTokens.toArray(spans);</b>
<b class="fc"><i>216</i>&nbsp;    return spans;</b>
<i>217</i>&nbsp;  }
<i>218</i>&nbsp;
<i>219</i>&nbsp;  /**
<i>220</i>&nbsp;   * Trains a model for the {@link TokenizerME}.
<i>221</i>&nbsp;   *
<i>222</i>&nbsp;   * @param samples
<i>223</i>&nbsp;   *          the samples used for the training.
<i>224</i>&nbsp;   * @param factory
<i>225</i>&nbsp;   *          a {@link TokenizerFactory} to get resources from
<i>226</i>&nbsp;   * @param mlParams
<i>227</i>&nbsp;   *          the machine learning train parameters
<i>228</i>&nbsp;   * @return the trained {@link TokenizerModel}
<i>229</i>&nbsp;   * @throws IOException
<i>230</i>&nbsp;   *           it throws an {@link IOException} if an {@link IOException} is
<i>231</i>&nbsp;   *           thrown during IO operations on a temp file which is created
<i>232</i>&nbsp;   *           during training. Or if reading from the {@link ObjectStream}
<i>233</i>&nbsp;   *           fails.
<i>234</i>&nbsp;   */
<i>235</i>&nbsp;  public static TokenizerModel train(ObjectStream&lt;TokenSample&gt; samples, TokenizerFactory factory,
<i>236</i>&nbsp;      TrainingParameters mlParams) throws IOException {
<i>237</i>&nbsp;
<b class="fc"><i>238</i>&nbsp;    Map&lt;String, String&gt; manifestInfoEntries = new HashMap&lt;&gt;();</b>
<i>239</i>&nbsp;
<b class="fc"><i>240</i>&nbsp;    ObjectStream&lt;Event&gt; eventStream = new TokSpanEventStream(samples,</b>
<b class="fc"><i>241</i>&nbsp;        factory.isUseAlphaNumericOptmization(),</b>
<b class="fc"><i>242</i>&nbsp;        factory.getAlphaNumericPattern(), factory.getContextGenerator());</b>
<i>243</i>&nbsp;
<b class="fc"><i>244</i>&nbsp;    EventTrainer trainer = TrainerFactory.getEventTrainer(</b>
<i>245</i>&nbsp;        mlParams, manifestInfoEntries);
<i>246</i>&nbsp;
<b class="fc"><i>247</i>&nbsp;    MaxentModel maxentModel = trainer.train(eventStream);</b>
<i>248</i>&nbsp;
<b class="fc"><i>249</i>&nbsp;    return new TokenizerModel(maxentModel, manifestInfoEntries, factory);</b>
<i>250</i>&nbsp;  }
<i>251</i>&nbsp;
<i>252</i>&nbsp;  /**
<i>253</i>&nbsp;   * Returns the value of the alpha-numeric optimization flag.
<i>254</i>&nbsp;   *
<i>255</i>&nbsp;   * @return true if the tokenizer should use alpha-numeric optimization, false otherwise.
<i>256</i>&nbsp;   */
<i>257</i>&nbsp;  public boolean useAlphaNumericOptimization() {
<b class="fc"><i>258</i>&nbsp;    return useAlphaNumericOptimization;</b>
<i>259</i>&nbsp;  }
<i>260</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-05-09 18:47</div>
</div>
</body>
</html>
