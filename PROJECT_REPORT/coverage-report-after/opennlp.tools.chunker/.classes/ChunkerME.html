


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: ChunkerME</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">opennlp.tools.chunker</a> ]
</div>

<h1>Coverage Summary for Class: ChunkerME (opennlp.tools.chunker)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">ChunkerME</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    70%
  </span>
  <span class="absValue">
    (7/ 10)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    60%
  </span>
  <span class="absValue">
    (30/ 50)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License. You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *     http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package opennlp.tools.chunker;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.io.IOException;
<i>21</i>&nbsp;import java.util.HashMap;
<i>22</i>&nbsp;import java.util.List;
<i>23</i>&nbsp;import java.util.Map;
<i>24</i>&nbsp;
<i>25</i>&nbsp;import opennlp.tools.ml.BeamSearch;
<i>26</i>&nbsp;import opennlp.tools.ml.EventTrainer;
<i>27</i>&nbsp;import opennlp.tools.ml.SequenceTrainer;
<i>28</i>&nbsp;import opennlp.tools.ml.TrainerFactory;
<i>29</i>&nbsp;import opennlp.tools.ml.TrainerFactory.TrainerType;
<i>30</i>&nbsp;import opennlp.tools.ml.model.Event;
<i>31</i>&nbsp;import opennlp.tools.ml.model.MaxentModel;
<i>32</i>&nbsp;import opennlp.tools.ml.model.SequenceClassificationModel;
<i>33</i>&nbsp;import opennlp.tools.util.ObjectStream;
<i>34</i>&nbsp;import opennlp.tools.util.Sequence;
<i>35</i>&nbsp;import opennlp.tools.util.SequenceValidator;
<i>36</i>&nbsp;import opennlp.tools.util.Span;
<i>37</i>&nbsp;import opennlp.tools.util.TokenTag;
<i>38</i>&nbsp;import opennlp.tools.util.TrainingParameters;
<i>39</i>&nbsp;
<i>40</i>&nbsp;/**
<i>41</i>&nbsp; * The class represents a maximum-entropy-based chunker.  Such a chunker can be used to
<i>42</i>&nbsp; * find flat structures based on sequence inputs such as noun phrases or named entities.
<i>43</i>&nbsp; */
<i>44</i>&nbsp;public class ChunkerME implements Chunker {
<i>45</i>&nbsp;
<i>46</i>&nbsp;  public static final int DEFAULT_BEAM_SIZE = 10;
<i>47</i>&nbsp;
<i>48</i>&nbsp;  private Sequence bestSequence;
<i>49</i>&nbsp;
<i>50</i>&nbsp;  /**
<i>51</i>&nbsp;   * The model used to assign chunk tags to a sequence of tokens.
<i>52</i>&nbsp;   */
<i>53</i>&nbsp;  protected SequenceClassificationModel&lt;TokenTag&gt; model;
<i>54</i>&nbsp;
<i>55</i>&nbsp;  private ChunkerContextGenerator contextGenerator;
<i>56</i>&nbsp;  private SequenceValidator&lt;TokenTag&gt; sequenceValidator;
<i>57</i>&nbsp;
<i>58</i>&nbsp;  /**
<i>59</i>&nbsp;   * Initializes the current instance with the specified model and
<i>60</i>&nbsp;   * the specified beam size.
<i>61</i>&nbsp;   *
<i>62</i>&nbsp;   * @param model The model for this chunker.
<i>63</i>&nbsp;   * @param beamSize The size of the beam that should be used when decoding sequences.
<i>64</i>&nbsp;   * @param sequenceValidator  The {@link SequenceValidator} to determines whether the outcome
<i>65</i>&nbsp;   *        is valid for the preceding sequence. This can be used to implement constraints
<i>66</i>&nbsp;   *        on what sequences are valid.
<i>67</i>&nbsp;   * @deprecated Use {@link #ChunkerME(ChunkerModel, int)} instead and use the {@link ChunkerFactory}
<i>68</i>&nbsp;   *     to configure the {@link SequenceValidator} and {@link ChunkerContextGenerator}.
<i>69</i>&nbsp;   */
<i>70</i>&nbsp;  @Deprecated
<i>71</i>&nbsp;  private ChunkerME(ChunkerModel model, int beamSize, SequenceValidator&lt;TokenTag&gt; sequenceValidator,
<b class="nc"><i>72</i>&nbsp;      ChunkerContextGenerator contextGenerator) {</b>
<i>73</i>&nbsp;
<b class="nc"><i>74</i>&nbsp;    this.sequenceValidator = sequenceValidator;</b>
<b class="nc"><i>75</i>&nbsp;    this.contextGenerator = contextGenerator;</b>
<i>76</i>&nbsp;
<b class="nc"><i>77</i>&nbsp;    if (model.getChunkerSequenceModel() != null) {</b>
<b class="nc"><i>78</i>&nbsp;      this.model = model.getChunkerSequenceModel();</b>
<i>79</i>&nbsp;    }
<i>80</i>&nbsp;    else {
<b class="nc"><i>81</i>&nbsp;      this.model = new opennlp.tools.ml.BeamSearch&lt;&gt;(beamSize,</b>
<b class="nc"><i>82</i>&nbsp;          model.getChunkerModel(), 0);</b>
<i>83</i>&nbsp;    }
<b class="nc"><i>84</i>&nbsp;  }</b>
<i>85</i>&nbsp;
<i>86</i>&nbsp;  /**
<i>87</i>&nbsp;   * Initializes the current instance with the specified model and
<i>88</i>&nbsp;   * the specified beam size.
<i>89</i>&nbsp;   *
<i>90</i>&nbsp;   * @param model The model for this chunker.
<i>91</i>&nbsp;   * @param beamSize The size of the beam that should be used when decoding sequences.
<i>92</i>&nbsp;   *
<i>93</i>&nbsp;   * @deprecated beam size is now stored inside the model
<i>94</i>&nbsp;   */
<i>95</i>&nbsp;  @Deprecated
<b class="fc"><i>96</i>&nbsp;  private ChunkerME(ChunkerModel model, int beamSize) {</b>
<i>97</i>&nbsp;
<b class="fc"><i>98</i>&nbsp;    contextGenerator = model.getFactory().getContextGenerator();</b>
<b class="fc"><i>99</i>&nbsp;    sequenceValidator = model.getFactory().getSequenceValidator();</b>
<i>100</i>&nbsp;
<b class="fc"><i>101</i>&nbsp;    if (model.getChunkerSequenceModel() != null) {</b>
<b class="fc"><i>102</i>&nbsp;      this.model = model.getChunkerSequenceModel();</b>
<i>103</i>&nbsp;    }
<i>104</i>&nbsp;    else {
<b class="nc"><i>105</i>&nbsp;      this.model = new opennlp.tools.ml.BeamSearch&lt;&gt;(beamSize,</b>
<b class="nc"><i>106</i>&nbsp;          model.getChunkerModel(), 0);</b>
<i>107</i>&nbsp;    }
<b class="fc"><i>108</i>&nbsp;  }</b>
<i>109</i>&nbsp;
<i>110</i>&nbsp;  /**
<i>111</i>&nbsp;   * Initializes the current instance with the specified model.
<i>112</i>&nbsp;   * The default beam size is used.
<i>113</i>&nbsp;   *
<i>114</i>&nbsp;   * @param model
<i>115</i>&nbsp;   */
<i>116</i>&nbsp;  public ChunkerME(ChunkerModel model) {
<b class="fc"><i>117</i>&nbsp;    this(model, DEFAULT_BEAM_SIZE);</b>
<b class="fc"><i>118</i>&nbsp;  }</b>
<i>119</i>&nbsp;
<i>120</i>&nbsp;  public String[] chunk(String[] toks, String[] tags) {
<b class="fc"><i>121</i>&nbsp;    TokenTag[] tuples = TokenTag.create(toks, tags);</b>
<b class="fc"><i>122</i>&nbsp;    bestSequence = model.bestSequence(tuples, new Object[] {}, contextGenerator, sequenceValidator);</b>
<b class="fc"><i>123</i>&nbsp;    List&lt;String&gt; c = bestSequence.getOutcomes();</b>
<b class="fc"><i>124</i>&nbsp;    return c.toArray(new String[c.size()]);</b>
<i>125</i>&nbsp;  }
<i>126</i>&nbsp;
<i>127</i>&nbsp;  public Span[] chunkAsSpans(String[] toks, String[] tags) {
<b class="fc"><i>128</i>&nbsp;    String[] preds = chunk(toks, tags);</b>
<b class="fc"><i>129</i>&nbsp;    return ChunkSample.phrasesAsSpanList(toks, tags, preds);</b>
<i>130</i>&nbsp;  }
<i>131</i>&nbsp;
<i>132</i>&nbsp;  public Sequence[] topKSequences(String[] sentence, String[] tags) {
<b class="fc"><i>133</i>&nbsp;    TokenTag[] tuples = TokenTag.create(sentence, tags);</b>
<i>134</i>&nbsp;
<b class="fc"><i>135</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, tuples,</b>
<i>136</i>&nbsp;        new Object[] { }, contextGenerator, sequenceValidator);
<i>137</i>&nbsp;  }
<i>138</i>&nbsp;
<i>139</i>&nbsp;  public Sequence[] topKSequences(String[] sentence, String[] tags, double minSequenceScore) {
<b class="fc"><i>140</i>&nbsp;    TokenTag[] tuples = TokenTag.create(sentence, tags);</b>
<b class="fc"><i>141</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, tuples, new Object[] { }, minSequenceScore,</b>
<i>142</i>&nbsp;        contextGenerator, sequenceValidator);
<i>143</i>&nbsp;  }
<i>144</i>&nbsp;
<i>145</i>&nbsp;  /**
<i>146</i>&nbsp;   * Populates the specified array with the probabilities of the last decoded sequence.  The
<i>147</i>&nbsp;   * sequence was determined based on the previous call to &lt;code&gt;chunk&lt;/code&gt;.  The
<i>148</i>&nbsp;   * specified array should be at least as large as the numbe of tokens in the previous
<i>149</i>&nbsp;   * call to &lt;code&gt;chunk&lt;/code&gt;.
<i>150</i>&nbsp;   *
<i>151</i>&nbsp;   * @param probs An array used to hold the probabilities of the last decoded sequence.
<i>152</i>&nbsp;   */
<i>153</i>&nbsp;  public void probs(double[] probs) {
<b class="nc"><i>154</i>&nbsp;    bestSequence.getProbs(probs);</b>
<b class="nc"><i>155</i>&nbsp;  }</b>
<i>156</i>&nbsp;
<i>157</i>&nbsp;  /**
<i>158</i>&nbsp;   * Returns an array with the probabilities of the last decoded sequence.  The
<i>159</i>&nbsp;   * sequence was determined based on the previous call to &lt;code&gt;chunk&lt;/code&gt;.
<i>160</i>&nbsp;   * @return An array with the same number of probabilities as tokens were sent to &lt;code&gt;chunk&lt;/code&gt;
<i>161</i>&nbsp;   *     when it was last called.
<i>162</i>&nbsp;   */
<i>163</i>&nbsp;  public double[] probs() {
<b class="nc"><i>164</i>&nbsp;    return bestSequence.getProbs();</b>
<i>165</i>&nbsp;  }
<i>166</i>&nbsp;
<i>167</i>&nbsp;  public static ChunkerModel train(String lang, ObjectStream&lt;ChunkSample&gt; in,
<i>168</i>&nbsp;      TrainingParameters mlParams, ChunkerFactory factory) throws IOException {
<i>169</i>&nbsp;
<b class="fc"><i>170</i>&nbsp;    int beamSize = mlParams.getIntParameter(BeamSearch.BEAM_SIZE_PARAMETER, ChunkerME.DEFAULT_BEAM_SIZE);</b>
<i>171</i>&nbsp;
<b class="fc"><i>172</i>&nbsp;    Map&lt;String, String&gt; manifestInfoEntries = new HashMap&lt;&gt;();</b>
<i>173</i>&nbsp;
<b class="fc"><i>174</i>&nbsp;    TrainerType trainerType = TrainerFactory.getTrainerType(mlParams);</b>
<i>175</i>&nbsp;
<i>176</i>&nbsp;
<b class="fc"><i>177</i>&nbsp;    MaxentModel chunkerModel = null;</b>
<b class="fc"><i>178</i>&nbsp;    SequenceClassificationModel&lt;String&gt; seqChunkerModel = null;</b>
<i>179</i>&nbsp;
<b class="fc"><i>180</i>&nbsp;    if (TrainerType.EVENT_MODEL_TRAINER.equals(trainerType)) {</b>
<b class="fc"><i>181</i>&nbsp;      ObjectStream&lt;Event&gt; es = new ChunkerEventStream(in, factory.getContextGenerator());</b>
<b class="fc"><i>182</i>&nbsp;      EventTrainer trainer = TrainerFactory.getEventTrainer(mlParams,</b>
<i>183</i>&nbsp;          manifestInfoEntries);
<b class="fc"><i>184</i>&nbsp;      chunkerModel = trainer.train(es);</b>
<b class="fc"><i>185</i>&nbsp;    }</b>
<b class="nc"><i>186</i>&nbsp;    else if (TrainerType.SEQUENCE_TRAINER.equals(trainerType)) {</b>
<b class="nc"><i>187</i>&nbsp;      SequenceTrainer trainer = TrainerFactory.getSequenceModelTrainer(</b>
<i>188</i>&nbsp;          mlParams, manifestInfoEntries);
<i>189</i>&nbsp;
<i>190</i>&nbsp;      // TODO: This will probably cause issue, since the feature generator uses the outcomes array
<i>191</i>&nbsp;
<b class="nc"><i>192</i>&nbsp;      ChunkSampleSequenceStream ss = new ChunkSampleSequenceStream(in, factory.getContextGenerator());</b>
<b class="nc"><i>193</i>&nbsp;      seqChunkerModel = trainer.train(ss);</b>
<b class="nc"><i>194</i>&nbsp;    }</b>
<i>195</i>&nbsp;    else {
<b class="nc"><i>196</i>&nbsp;      throw new IllegalArgumentException(&quot;Trainer type is not supported: &quot; + trainerType);</b>
<i>197</i>&nbsp;    }
<i>198</i>&nbsp;
<b class="fc"><i>199</i>&nbsp;    if (chunkerModel != null) {</b>
<b class="fc"><i>200</i>&nbsp;      return new ChunkerModel(lang, chunkerModel, beamSize, manifestInfoEntries, factory);</b>
<i>201</i>&nbsp;    }
<i>202</i>&nbsp;    else {
<b class="nc"><i>203</i>&nbsp;      return new ChunkerModel(lang, seqChunkerModel, manifestInfoEntries, factory);</b>
<i>204</i>&nbsp;    }
<i>205</i>&nbsp;  }
<i>206</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-05-09 18:47</div>
</div>
</body>
</html>
