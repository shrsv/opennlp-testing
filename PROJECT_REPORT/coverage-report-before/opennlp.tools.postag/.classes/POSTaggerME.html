


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: POSTaggerME</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">opennlp.tools.postag</a> ]
</div>

<h1>Coverage Summary for Class: POSTaggerME (opennlp.tools.postag)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">POSTaggerME</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    35.7%
  </span>
  <span class="absValue">
    (5/ 14)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    32.8%
  </span>
  <span class="absValue">
    (40/ 122)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License. You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *     http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package opennlp.tools.postag;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.io.IOException;
<i>21</i>&nbsp;import java.util.ArrayList;
<i>22</i>&nbsp;import java.util.HashMap;
<i>23</i>&nbsp;import java.util.List;
<i>24</i>&nbsp;import java.util.Map;
<i>25</i>&nbsp;import java.util.Map.Entry;
<i>26</i>&nbsp;import java.util.concurrent.atomic.AtomicInteger;
<i>27</i>&nbsp;
<i>28</i>&nbsp;import opennlp.tools.dictionary.Dictionary;
<i>29</i>&nbsp;import opennlp.tools.ml.BeamSearch;
<i>30</i>&nbsp;import opennlp.tools.ml.EventModelSequenceTrainer;
<i>31</i>&nbsp;import opennlp.tools.ml.EventTrainer;
<i>32</i>&nbsp;import opennlp.tools.ml.SequenceTrainer;
<i>33</i>&nbsp;import opennlp.tools.ml.TrainerFactory;
<i>34</i>&nbsp;import opennlp.tools.ml.TrainerFactory.TrainerType;
<i>35</i>&nbsp;import opennlp.tools.ml.model.Event;
<i>36</i>&nbsp;import opennlp.tools.ml.model.MaxentModel;
<i>37</i>&nbsp;import opennlp.tools.ml.model.SequenceClassificationModel;
<i>38</i>&nbsp;import opennlp.tools.ngram.NGramModel;
<i>39</i>&nbsp;import opennlp.tools.util.ObjectStream;
<i>40</i>&nbsp;import opennlp.tools.util.Sequence;
<i>41</i>&nbsp;import opennlp.tools.util.SequenceValidator;
<i>42</i>&nbsp;import opennlp.tools.util.StringList;
<i>43</i>&nbsp;import opennlp.tools.util.StringUtil;
<i>44</i>&nbsp;import opennlp.tools.util.TrainingParameters;
<i>45</i>&nbsp;import opennlp.tools.util.featuregen.StringPattern;
<i>46</i>&nbsp;
<i>47</i>&nbsp;/**
<i>48</i>&nbsp; * A part-of-speech tagger that uses maximum entropy.  Tries to predict whether
<i>49</i>&nbsp; * words are nouns, verbs, or any of 70 other POS tags depending on their
<i>50</i>&nbsp; * surrounding context.
<i>51</i>&nbsp; *
<i>52</i>&nbsp; */
<i>53</i>&nbsp;public class POSTaggerME implements POSTagger {
<i>54</i>&nbsp;
<i>55</i>&nbsp;  public static final int DEFAULT_BEAM_SIZE = 3;
<i>56</i>&nbsp;
<i>57</i>&nbsp;  private POSModel modelPackage;
<i>58</i>&nbsp;
<i>59</i>&nbsp;  /**
<i>60</i>&nbsp;   * The feature context generator.
<i>61</i>&nbsp;   */
<i>62</i>&nbsp;  protected POSContextGenerator contextGen;
<i>63</i>&nbsp;
<i>64</i>&nbsp;  /**
<i>65</i>&nbsp;   * Tag dictionary used for restricting words to a fixed set of tags.
<i>66</i>&nbsp;   */
<i>67</i>&nbsp;  protected TagDictionary tagDictionary;
<i>68</i>&nbsp;
<i>69</i>&nbsp;  protected Dictionary ngramDictionary;
<i>70</i>&nbsp;
<i>71</i>&nbsp;  /**
<i>72</i>&nbsp;   * Says whether a filter should be used to check whether a tag assignment
<i>73</i>&nbsp;   * is to a word outside of a closed class.
<i>74</i>&nbsp;   */
<b class="fc"><i>75</i>&nbsp;  protected boolean useClosedClassTagsFilter = false;</b>
<i>76</i>&nbsp;
<i>77</i>&nbsp;
<i>78</i>&nbsp;  /**
<i>79</i>&nbsp;   * The size of the beam to be used in determining the best sequence of pos tags.
<i>80</i>&nbsp;   */
<i>81</i>&nbsp;  protected int size;
<i>82</i>&nbsp;
<i>83</i>&nbsp;  private Sequence bestSequence;
<i>84</i>&nbsp;
<i>85</i>&nbsp;  private SequenceClassificationModel&lt;String&gt; model;
<i>86</i>&nbsp;
<i>87</i>&nbsp;  private SequenceValidator&lt;String&gt; sequenceValidator;
<i>88</i>&nbsp;
<i>89</i>&nbsp;  /**
<i>90</i>&nbsp;   * Initializes the current instance with the provided model.
<i>91</i>&nbsp;   *
<i>92</i>&nbsp;   * @param model
<i>93</i>&nbsp;   */
<b class="fc"><i>94</i>&nbsp;  public POSTaggerME(POSModel model) {</b>
<b class="fc"><i>95</i>&nbsp;    POSTaggerFactory factory = model.getFactory();</b>
<i>96</i>&nbsp;
<b class="fc"><i>97</i>&nbsp;    int beamSize = POSTaggerME.DEFAULT_BEAM_SIZE;</b>
<i>98</i>&nbsp;
<b class="fc"><i>99</i>&nbsp;    String beamSizeString = model.getManifestProperty(BeamSearch.BEAM_SIZE_PARAMETER);</b>
<i>100</i>&nbsp;
<b class="fc"><i>101</i>&nbsp;    if (beamSizeString != null) {</b>
<b class="fc"><i>102</i>&nbsp;      beamSize = Integer.parseInt(beamSizeString);</b>
<i>103</i>&nbsp;    }
<i>104</i>&nbsp;
<b class="fc"><i>105</i>&nbsp;    modelPackage = model;</b>
<i>106</i>&nbsp;
<b class="fc"><i>107</i>&nbsp;    contextGen = factory.getPOSContextGenerator(beamSize);</b>
<b class="fc"><i>108</i>&nbsp;    tagDictionary = factory.getTagDictionary();</b>
<b class="fc"><i>109</i>&nbsp;    size = beamSize;</b>
<i>110</i>&nbsp;
<b class="fc"><i>111</i>&nbsp;    sequenceValidator = factory.getSequenceValidator();</b>
<i>112</i>&nbsp;
<b class="fc"><i>113</i>&nbsp;    if (model.getPosSequenceModel() != null) {</b>
<b class="fc"><i>114</i>&nbsp;      this.model = model.getPosSequenceModel();</b>
<i>115</i>&nbsp;    }
<i>116</i>&nbsp;    else {
<b class="nc"><i>117</i>&nbsp;      this.model = new opennlp.tools.ml.BeamSearch&lt;&gt;(beamSize,</b>
<b class="nc"><i>118</i>&nbsp;          model.getPosModel(), 0);</b>
<i>119</i>&nbsp;    }
<i>120</i>&nbsp;
<b class="fc"><i>121</i>&nbsp;  }</b>
<i>122</i>&nbsp;
<i>123</i>&nbsp;  /**
<i>124</i>&nbsp;   * Retrieves an array of all possible part-of-speech tags from the
<i>125</i>&nbsp;   * tagger.
<i>126</i>&nbsp;   *
<i>127</i>&nbsp;   * @return String[]
<i>128</i>&nbsp;   */
<i>129</i>&nbsp;  public String[] getAllPosTags() {
<b class="nc"><i>130</i>&nbsp;    return model.getOutcomes();</b>
<i>131</i>&nbsp;  }
<i>132</i>&nbsp;
<i>133</i>&nbsp;  public String[] tag(String[] sentence) {
<b class="fc"><i>134</i>&nbsp;    return this.tag(sentence, null);</b>
<i>135</i>&nbsp;  }
<i>136</i>&nbsp;
<i>137</i>&nbsp;  public String[] tag(String[] sentence, Object[] additionaContext) {
<b class="fc"><i>138</i>&nbsp;    bestSequence = model.bestSequence(sentence, additionaContext, contextGen, sequenceValidator);</b>
<b class="fc"><i>139</i>&nbsp;    List&lt;String&gt; t = bestSequence.getOutcomes();</b>
<b class="fc"><i>140</i>&nbsp;    return t.toArray(new String[t.size()]);</b>
<i>141</i>&nbsp;  }
<i>142</i>&nbsp;
<i>143</i>&nbsp;  /**
<i>144</i>&nbsp;   * Returns at most the specified number of taggings for the specified sentence.
<i>145</i>&nbsp;   *
<i>146</i>&nbsp;   * @param numTaggings The number of tagging to be returned.
<i>147</i>&nbsp;   * @param sentence An array of tokens which make up a sentence.
<i>148</i>&nbsp;   *
<i>149</i>&nbsp;   * @return At most the specified number of taggings for the specified sentence.
<i>150</i>&nbsp;   */
<i>151</i>&nbsp;  public String[][] tag(int numTaggings, String[] sentence) {
<b class="nc"><i>152</i>&nbsp;    Sequence[] bestSequences = model.bestSequences(numTaggings, sentence, null,</b>
<i>153</i>&nbsp;        contextGen, sequenceValidator);
<b class="nc"><i>154</i>&nbsp;    String[][] tags = new String[bestSequences.length][];</b>
<b class="nc"><i>155</i>&nbsp;    for (int si = 0; si &lt; tags.length; si++) {</b>
<b class="nc"><i>156</i>&nbsp;      List&lt;String&gt; t = bestSequences[si].getOutcomes();</b>
<b class="nc"><i>157</i>&nbsp;      tags[si] = t.toArray(new String[t.size()]);</b>
<i>158</i>&nbsp;    }
<b class="nc"><i>159</i>&nbsp;    return tags;</b>
<i>160</i>&nbsp;  }
<i>161</i>&nbsp;
<i>162</i>&nbsp;  public Sequence[] topKSequences(String[] sentence) {
<b class="nc"><i>163</i>&nbsp;    return this.topKSequences(sentence, null);</b>
<i>164</i>&nbsp;  }
<i>165</i>&nbsp;
<i>166</i>&nbsp;  public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {
<b class="nc"><i>167</i>&nbsp;    return model.bestSequences(size, sentence, additionaContext, contextGen, sequenceValidator);</b>
<i>168</i>&nbsp;  }
<i>169</i>&nbsp;
<i>170</i>&nbsp;  /**
<i>171</i>&nbsp;   * Populates the specified array with the probabilities for each tag of the last tagged sentence.
<i>172</i>&nbsp;   *
<i>173</i>&nbsp;   * @param probs An array to put the probabilities into.
<i>174</i>&nbsp;   */
<i>175</i>&nbsp;  public void probs(double[] probs) {
<b class="nc"><i>176</i>&nbsp;    bestSequence.getProbs(probs);</b>
<b class="nc"><i>177</i>&nbsp;  }</b>
<i>178</i>&nbsp;
<i>179</i>&nbsp;  /**
<i>180</i>&nbsp;   * Returns an array with the probabilities for each tag of the last tagged sentence.
<i>181</i>&nbsp;   *
<i>182</i>&nbsp;   * @return an array with the probabilities for each tag of the last tagged sentence.
<i>183</i>&nbsp;   */
<i>184</i>&nbsp;  public double[] probs() {
<b class="nc"><i>185</i>&nbsp;    return bestSequence.getProbs();</b>
<i>186</i>&nbsp;  }
<i>187</i>&nbsp;
<i>188</i>&nbsp;  public String[] getOrderedTags(List&lt;String&gt; words, List&lt;String&gt; tags, int index) {
<b class="nc"><i>189</i>&nbsp;    return getOrderedTags(words,tags,index,null);</b>
<i>190</i>&nbsp;  }
<i>191</i>&nbsp;
<i>192</i>&nbsp;  public String[] getOrderedTags(List&lt;String&gt; words, List&lt;String&gt; tags, int index,double[] tprobs) {
<i>193</i>&nbsp;
<b class="nc"><i>194</i>&nbsp;    if (modelPackage.getPosModel() != null) {</b>
<i>195</i>&nbsp;
<b class="nc"><i>196</i>&nbsp;      MaxentModel posModel = modelPackage.getPosModel();</b>
<i>197</i>&nbsp;
<b class="nc"><i>198</i>&nbsp;      double[] probs = posModel.eval(contextGen.getContext(index,</b>
<b class="nc"><i>199</i>&nbsp;          words.toArray(new String[words.size()]),</b>
<b class="nc"><i>200</i>&nbsp;          tags.toArray(new String[tags.size()]),null));</b>
<i>201</i>&nbsp;
<b class="nc"><i>202</i>&nbsp;      String[] orderedTags = new String[probs.length];</b>
<b class="nc"><i>203</i>&nbsp;      for (int i = 0; i &lt; probs.length; i++) {</b>
<b class="nc"><i>204</i>&nbsp;        int max = 0;</b>
<b class="nc"><i>205</i>&nbsp;        for (int ti = 1; ti &lt; probs.length; ti++) {</b>
<b class="nc"><i>206</i>&nbsp;          if (probs[ti] &gt; probs[max]) {</b>
<b class="nc"><i>207</i>&nbsp;            max = ti;</b>
<i>208</i>&nbsp;          }
<i>209</i>&nbsp;        }
<b class="nc"><i>210</i>&nbsp;        orderedTags[i] = posModel.getOutcome(max);</b>
<b class="nc"><i>211</i>&nbsp;        if (tprobs != null) {</b>
<b class="nc"><i>212</i>&nbsp;          tprobs[i] = probs[max];</b>
<i>213</i>&nbsp;        }
<b class="nc"><i>214</i>&nbsp;        probs[max] = 0;</b>
<i>215</i>&nbsp;      }
<b class="nc"><i>216</i>&nbsp;      return orderedTags;</b>
<i>217</i>&nbsp;    }
<i>218</i>&nbsp;    else {
<b class="nc"><i>219</i>&nbsp;      throw new UnsupportedOperationException(&quot;This method can only be called if the &quot;</b>
<i>220</i>&nbsp;          + &quot;classifcation model is an event model!&quot;);
<i>221</i>&nbsp;    }
<i>222</i>&nbsp;  }
<i>223</i>&nbsp;
<i>224</i>&nbsp;  public static POSModel train(String languageCode,
<i>225</i>&nbsp;      ObjectStream&lt;POSSample&gt; samples, TrainingParameters trainParams,
<i>226</i>&nbsp;      POSTaggerFactory posFactory) throws IOException {
<i>227</i>&nbsp;
<b class="fc"><i>228</i>&nbsp;    int beamSize = trainParams.getIntParameter(BeamSearch.BEAM_SIZE_PARAMETER, POSTaggerME.DEFAULT_BEAM_SIZE);</b>
<i>229</i>&nbsp;
<b class="fc"><i>230</i>&nbsp;    POSContextGenerator contextGenerator = posFactory.getPOSContextGenerator();</b>
<i>231</i>&nbsp;
<b class="fc"><i>232</i>&nbsp;    Map&lt;String, String&gt; manifestInfoEntries = new HashMap&lt;&gt;();</b>
<i>233</i>&nbsp;
<b class="fc"><i>234</i>&nbsp;    TrainerType trainerType = TrainerFactory.getTrainerType(trainParams);</b>
<i>235</i>&nbsp;
<b class="fc"><i>236</i>&nbsp;    MaxentModel posModel = null;</b>
<b class="fc"><i>237</i>&nbsp;    SequenceClassificationModel&lt;String&gt; seqPosModel = null;</b>
<b class="fc"><i>238</i>&nbsp;    if (TrainerType.EVENT_MODEL_TRAINER.equals(trainerType)) {</b>
<b class="fc"><i>239</i>&nbsp;      ObjectStream&lt;Event&gt; es = new POSSampleEventStream(samples, contextGenerator);</b>
<i>240</i>&nbsp;
<b class="fc"><i>241</i>&nbsp;      EventTrainer trainer = TrainerFactory.getEventTrainer(trainParams,</b>
<i>242</i>&nbsp;          manifestInfoEntries);
<b class="fc"><i>243</i>&nbsp;      posModel = trainer.train(es);</b>
<b class="fc"><i>244</i>&nbsp;    }</b>
<b class="nc"><i>245</i>&nbsp;    else if (TrainerType.EVENT_MODEL_SEQUENCE_TRAINER.equals(trainerType)) {</b>
<b class="nc"><i>246</i>&nbsp;      POSSampleSequenceStream ss = new POSSampleSequenceStream(samples, contextGenerator);</b>
<b class="nc"><i>247</i>&nbsp;      EventModelSequenceTrainer trainer =</b>
<b class="nc"><i>248</i>&nbsp;          TrainerFactory.getEventModelSequenceTrainer(trainParams, manifestInfoEntries);</b>
<b class="nc"><i>249</i>&nbsp;      posModel = trainer.train(ss);</b>
<b class="nc"><i>250</i>&nbsp;    }</b>
<b class="nc"><i>251</i>&nbsp;    else if (TrainerType.SEQUENCE_TRAINER.equals(trainerType)) {</b>
<b class="nc"><i>252</i>&nbsp;      SequenceTrainer trainer = TrainerFactory.getSequenceModelTrainer(</b>
<i>253</i>&nbsp;          trainParams, manifestInfoEntries);
<i>254</i>&nbsp;
<i>255</i>&nbsp;      // TODO: This will probably cause issue, since the feature generator uses the outcomes array
<i>256</i>&nbsp;
<b class="nc"><i>257</i>&nbsp;      POSSampleSequenceStream ss = new POSSampleSequenceStream(samples, contextGenerator);</b>
<b class="nc"><i>258</i>&nbsp;      seqPosModel = trainer.train(ss);</b>
<b class="nc"><i>259</i>&nbsp;    }</b>
<i>260</i>&nbsp;    else {
<b class="nc"><i>261</i>&nbsp;      throw new IllegalArgumentException(&quot;Trainer type is not supported: &quot; + trainerType);</b>
<i>262</i>&nbsp;    }
<i>263</i>&nbsp;
<b class="fc"><i>264</i>&nbsp;    if (posModel != null) {</b>
<b class="fc"><i>265</i>&nbsp;      return new POSModel(languageCode, posModel, beamSize, manifestInfoEntries, posFactory);</b>
<i>266</i>&nbsp;    }
<i>267</i>&nbsp;    else {
<b class="nc"><i>268</i>&nbsp;      return new POSModel(languageCode, seqPosModel, manifestInfoEntries, posFactory);</b>
<i>269</i>&nbsp;    }
<i>270</i>&nbsp;  }
<i>271</i>&nbsp;
<i>272</i>&nbsp;  public static Dictionary buildNGramDictionary(ObjectStream&lt;POSSample&gt; samples, int cutoff)
<i>273</i>&nbsp;      throws IOException {
<i>274</i>&nbsp;
<b class="fc"><i>275</i>&nbsp;    NGramModel ngramModel = new NGramModel();</b>
<i>276</i>&nbsp;
<i>277</i>&nbsp;    POSSample sample;
<b class="fc"><i>278</i>&nbsp;    while ((sample = samples.read()) != null) {</b>
<b class="fc"><i>279</i>&nbsp;      String[] words = sample.getSentence();</b>
<i>280</i>&nbsp;
<b class="fc"><i>281</i>&nbsp;      if (words.length &gt; 0)</b>
<b class="fc"><i>282</i>&nbsp;        ngramModel.add(new StringList(words), 1, 1);</b>
<b class="fc"><i>283</i>&nbsp;    }</b>
<i>284</i>&nbsp;
<b class="fc"><i>285</i>&nbsp;    ngramModel.cutoff(cutoff, Integer.MAX_VALUE);</b>
<i>286</i>&nbsp;
<b class="fc"><i>287</i>&nbsp;    return ngramModel.toDictionary(true);</b>
<i>288</i>&nbsp;  }
<i>289</i>&nbsp;
<i>290</i>&nbsp;  public static void populatePOSDictionary(ObjectStream&lt;POSSample&gt; samples,
<i>291</i>&nbsp;      MutableTagDictionary dict, int cutoff) throws IOException {
<b class="nc"><i>292</i>&nbsp;    System.out.println(&quot;Expanding POS Dictionary ...&quot;);</b>
<b class="nc"><i>293</i>&nbsp;    long start = System.nanoTime();</b>
<i>294</i>&nbsp;
<i>295</i>&nbsp;    // the data structure will store the word, the tag, and the number of
<i>296</i>&nbsp;    // occurrences
<b class="nc"><i>297</i>&nbsp;    Map&lt;String, Map&lt;String, AtomicInteger&gt;&gt; newEntries = new HashMap&lt;&gt;();</b>
<i>298</i>&nbsp;    POSSample sample;
<b class="nc"><i>299</i>&nbsp;    while ((sample = samples.read()) != null) {</b>
<b class="nc"><i>300</i>&nbsp;      String[] words = sample.getSentence();</b>
<b class="nc"><i>301</i>&nbsp;      String[] tags = sample.getTags();</b>
<i>302</i>&nbsp;
<b class="nc"><i>303</i>&nbsp;      for (int i = 0; i &lt; words.length; i++) {</b>
<i>304</i>&nbsp;        // only store words
<b class="nc"><i>305</i>&nbsp;        if (!StringPattern.recognize(words[i]).containsDigit()) {</b>
<i>306</i>&nbsp;          String word;
<b class="nc"><i>307</i>&nbsp;          if (dict.isCaseSensitive()) {</b>
<b class="nc"><i>308</i>&nbsp;            word = words[i];</b>
<i>309</i>&nbsp;          } else {
<b class="nc"><i>310</i>&nbsp;            word = StringUtil.toLowerCase(words[i]);</b>
<i>311</i>&nbsp;          }
<i>312</i>&nbsp;
<b class="nc"><i>313</i>&nbsp;          if (!newEntries.containsKey(word)) {</b>
<b class="nc"><i>314</i>&nbsp;            newEntries.put(word, new HashMap&lt;&gt;());</b>
<i>315</i>&nbsp;          }
<i>316</i>&nbsp;
<b class="nc"><i>317</i>&nbsp;          String[] dictTags = dict.getTags(word);</b>
<b class="nc"><i>318</i>&nbsp;          if (dictTags != null) {</b>
<b class="nc"><i>319</i>&nbsp;            for (String tag : dictTags) {</b>
<i>320</i>&nbsp;              // for this tags we start with the cutoff
<b class="nc"><i>321</i>&nbsp;              Map&lt;String, AtomicInteger&gt; value = newEntries.get(word);</b>
<b class="nc"><i>322</i>&nbsp;              if (!value.containsKey(tag)) {</b>
<b class="nc"><i>323</i>&nbsp;                value.put(tag, new AtomicInteger(cutoff));</b>
<i>324</i>&nbsp;              }
<i>325</i>&nbsp;            }
<i>326</i>&nbsp;          }
<i>327</i>&nbsp;
<b class="nc"><i>328</i>&nbsp;          if (!newEntries.get(word).containsKey(tags[i])) {</b>
<b class="nc"><i>329</i>&nbsp;            newEntries.get(word).put(tags[i], new AtomicInteger(1));</b>
<i>330</i>&nbsp;          } else {
<b class="nc"><i>331</i>&nbsp;            newEntries.get(word).get(tags[i]).incrementAndGet();</b>
<i>332</i>&nbsp;          }
<i>333</i>&nbsp;        }
<i>334</i>&nbsp;      }
<b class="nc"><i>335</i>&nbsp;    }</b>
<i>336</i>&nbsp;
<i>337</i>&nbsp;    // now we check if the word + tag pairs have enough occurrences, if yes we
<i>338</i>&nbsp;    // add it to the dictionary
<b class="nc"><i>339</i>&nbsp;    for (Entry&lt;String, Map&lt;String, AtomicInteger&gt;&gt; wordEntry : newEntries</b>
<b class="nc"><i>340</i>&nbsp;        .entrySet()) {</b>
<b class="nc"><i>341</i>&nbsp;      List&lt;String&gt; tagsForWord = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>342</i>&nbsp;      for (Entry&lt;String, AtomicInteger&gt; entry : wordEntry.getValue().entrySet()) {</b>
<b class="nc"><i>343</i>&nbsp;        if (entry.getValue().get() &gt;= cutoff) {</b>
<b class="nc"><i>344</i>&nbsp;          tagsForWord.add(entry.getKey());</b>
<i>345</i>&nbsp;        }
<b class="nc"><i>346</i>&nbsp;      }</b>
<b class="nc"><i>347</i>&nbsp;      if (tagsForWord.size() &gt; 0) {</b>
<b class="nc"><i>348</i>&nbsp;        dict.put(wordEntry.getKey(),</b>
<b class="nc"><i>349</i>&nbsp;            tagsForWord.toArray(new String[tagsForWord.size()]));</b>
<i>350</i>&nbsp;      }
<b class="nc"><i>351</i>&nbsp;    }</b>
<i>352</i>&nbsp;
<b class="nc"><i>353</i>&nbsp;    System.out.println(&quot;... finished expanding POS Dictionary. [&quot;</b>
<b class="nc"><i>354</i>&nbsp;        + (System.nanoTime() - start) / 1000000 + &quot;ms]&quot;);</b>
<b class="nc"><i>355</i>&nbsp;  }</b>
<i>356</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-05-09 15:05</div>
</div>
</body>
</html>
