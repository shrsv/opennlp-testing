


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: LemmatizerME</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">opennlp.tools.lemmatizer</a> ]
</div>

<h1>Coverage Summary for Class: LemmatizerME (opennlp.tools.lemmatizer)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">LemmatizerME</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    42.9%
  </span>
  <span class="absValue">
    (6/ 14)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    53.1%
  </span>
  <span class="absValue">
    (43/ 81)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;/*
<i>2</i>&nbsp; * Licensed to the Apache Software Foundation (ASF) under one or more
<i>3</i>&nbsp; * contributor license agreements.  See the NOTICE file distributed with
<i>4</i>&nbsp; * this work for additional information regarding copyright ownership.
<i>5</i>&nbsp; * The ASF licenses this file to You under the Apache License, Version 2.0
<i>6</i>&nbsp; * (the &quot;License&quot;); you may not use this file except in compliance with
<i>7</i>&nbsp; * the License. You may obtain a copy of the License at
<i>8</i>&nbsp; *
<i>9</i>&nbsp; *     http://www.apache.org/licenses/LICENSE-2.0
<i>10</i>&nbsp; *
<i>11</i>&nbsp; * Unless required by applicable law or agreed to in writing, software
<i>12</i>&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<i>13</i>&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<i>14</i>&nbsp; * See the License for the specific language governing permissions and
<i>15</i>&nbsp; * limitations under the License.
<i>16</i>&nbsp; */
<i>17</i>&nbsp;
<i>18</i>&nbsp;package opennlp.tools.lemmatizer;
<i>19</i>&nbsp;
<i>20</i>&nbsp;import java.io.IOException;
<i>21</i>&nbsp;import java.util.ArrayList;
<i>22</i>&nbsp;import java.util.Arrays;
<i>23</i>&nbsp;import java.util.HashMap;
<i>24</i>&nbsp;import java.util.List;
<i>25</i>&nbsp;import java.util.Map;
<i>26</i>&nbsp;
<i>27</i>&nbsp;import opennlp.tools.ml.BeamSearch;
<i>28</i>&nbsp;import opennlp.tools.ml.EventModelSequenceTrainer;
<i>29</i>&nbsp;import opennlp.tools.ml.EventTrainer;
<i>30</i>&nbsp;import opennlp.tools.ml.SequenceTrainer;
<i>31</i>&nbsp;import opennlp.tools.ml.TrainerFactory;
<i>32</i>&nbsp;import opennlp.tools.ml.TrainerFactory.TrainerType;
<i>33</i>&nbsp;import opennlp.tools.ml.model.Event;
<i>34</i>&nbsp;import opennlp.tools.ml.model.MaxentModel;
<i>35</i>&nbsp;import opennlp.tools.ml.model.SequenceClassificationModel;
<i>36</i>&nbsp;import opennlp.tools.util.ObjectStream;
<i>37</i>&nbsp;import opennlp.tools.util.Sequence;
<i>38</i>&nbsp;import opennlp.tools.util.SequenceValidator;
<i>39</i>&nbsp;import opennlp.tools.util.StringUtil;
<i>40</i>&nbsp;import opennlp.tools.util.TrainingParameters;
<i>41</i>&nbsp;
<i>42</i>&nbsp;/**
<i>43</i>&nbsp; * A probabilistic lemmatizer.  Tries to predict the induced permutation class
<i>44</i>&nbsp; * for each word depending on its surrounding context. Based on
<i>45</i>&nbsp; * Grzegorz Chrupa≈Ça. 2008. Towards a Machine-Learning Architecture
<i>46</i>&nbsp; * for Lexical Functional Grammar Parsing. PhD dissertation, Dublin City University.
<i>47</i>&nbsp; * http://grzegorz.chrupala.me/papers/phd-single.pdf
<i>48</i>&nbsp; */
<i>49</i>&nbsp;public class LemmatizerME implements Lemmatizer {
<i>50</i>&nbsp;
<i>51</i>&nbsp;  public static final int LEMMA_NUMBER = 29;
<i>52</i>&nbsp;  public static final int DEFAULT_BEAM_SIZE = 3;
<i>53</i>&nbsp;  protected int beamSize;
<i>54</i>&nbsp;  private Sequence bestSequence;
<i>55</i>&nbsp;
<i>56</i>&nbsp;  private SequenceClassificationModel&lt;String&gt; model;
<i>57</i>&nbsp;
<i>58</i>&nbsp;  private LemmatizerContextGenerator contextGenerator;
<i>59</i>&nbsp;  private SequenceValidator&lt;String&gt; sequenceValidator;
<i>60</i>&nbsp;
<i>61</i>&nbsp;  /**
<i>62</i>&nbsp;   * Initializes the current instance with the provided model
<i>63</i>&nbsp;   * and the default beam size of 3.
<i>64</i>&nbsp;   *
<i>65</i>&nbsp;   * @param model the model
<i>66</i>&nbsp;   */
<b class="fc"><i>67</i>&nbsp;  public LemmatizerME(LemmatizerModel model) {</b>
<i>68</i>&nbsp;
<b class="fc"><i>69</i>&nbsp;    LemmatizerFactory factory = model.getFactory();</b>
<b class="fc"><i>70</i>&nbsp;    int defaultBeamSize = LemmatizerME.DEFAULT_BEAM_SIZE;</b>
<b class="fc"><i>71</i>&nbsp;    String beamSizeString = model.getManifestProperty(BeamSearch.BEAM_SIZE_PARAMETER);</b>
<b class="fc"><i>72</i>&nbsp;    if (beamSizeString != null) {</b>
<b class="fc"><i>73</i>&nbsp;      defaultBeamSize = Integer.parseInt(beamSizeString);</b>
<i>74</i>&nbsp;    }
<i>75</i>&nbsp;
<b class="fc"><i>76</i>&nbsp;    contextGenerator = factory.getContextGenerator();</b>
<b class="fc"><i>77</i>&nbsp;    beamSize = defaultBeamSize;</b>
<i>78</i>&nbsp;
<b class="fc"><i>79</i>&nbsp;    sequenceValidator = factory.getSequenceValidator();</b>
<i>80</i>&nbsp;
<b class="fc"><i>81</i>&nbsp;    if (model.getLemmatizerSequenceModel() != null) {</b>
<b class="fc"><i>82</i>&nbsp;      this.model = model.getLemmatizerSequenceModel();</b>
<i>83</i>&nbsp;    }
<i>84</i>&nbsp;    else {
<b class="nc"><i>85</i>&nbsp;      this.model = new opennlp.tools.ml.BeamSearch&lt;&gt;(beamSize,</b>
<b class="nc"><i>86</i>&nbsp;          (MaxentModel) model.getLemmatizerSequenceModel(), 0);</b>
<i>87</i>&nbsp;    }
<b class="fc"><i>88</i>&nbsp;  }</b>
<i>89</i>&nbsp;
<i>90</i>&nbsp;  public String[] lemmatize(String[] toks, String[] tags) {
<b class="fc"><i>91</i>&nbsp;    String[] ses = predictSES(toks, tags);</b>
<b class="fc"><i>92</i>&nbsp;    String[] lemmas = decodeLemmas(toks, ses);</b>
<b class="fc"><i>93</i>&nbsp;    return lemmas;</b>
<i>94</i>&nbsp;  }
<i>95</i>&nbsp;
<i>96</i>&nbsp;  @Override public List&lt;List&lt;String&gt;&gt; lemmatize(List&lt;String&gt; toks,
<i>97</i>&nbsp;      List&lt;String&gt; tags) {
<b class="nc"><i>98</i>&nbsp;    String[] tokens = toks.toArray(new String[toks.size()]);</b>
<b class="nc"><i>99</i>&nbsp;    String[] posTags = tags.toArray(new String[tags.size()]);</b>
<b class="nc"><i>100</i>&nbsp;    String[][] allLemmas = predictLemmas(LEMMA_NUMBER, tokens, posTags);</b>
<b class="nc"><i>101</i>&nbsp;    List&lt;List&lt;String&gt;&gt; predictedLemmas = new ArrayList&lt;&gt;();</b>
<b class="nc"><i>102</i>&nbsp;    for (int i = 0; i &lt; allLemmas.length; i++) {</b>
<b class="nc"><i>103</i>&nbsp;      predictedLemmas.add(Arrays.asList(allLemmas[i]));</b>
<i>104</i>&nbsp;    }
<b class="nc"><i>105</i>&nbsp;    return predictedLemmas;</b>
<i>106</i>&nbsp;  }
<i>107</i>&nbsp;
<i>108</i>&nbsp;  /**
<i>109</i>&nbsp;   * Predict Short Edit Script (automatically induced lemma class).
<i>110</i>&nbsp;   * @param toks the array of tokens
<i>111</i>&nbsp;   * @param tags the array of pos tags
<i>112</i>&nbsp;   * @return an array containing the lemma classes
<i>113</i>&nbsp;   */
<i>114</i>&nbsp;  public String[] predictSES(String[] toks, String[] tags) {
<b class="fc"><i>115</i>&nbsp;    bestSequence = model.bestSequence(toks, new Object[] {tags}, contextGenerator, sequenceValidator);</b>
<b class="fc"><i>116</i>&nbsp;    List&lt;String&gt; ses = bestSequence.getOutcomes();</b>
<b class="fc"><i>117</i>&nbsp;    return ses.toArray(new String[ses.size()]);</b>
<i>118</i>&nbsp;  }
<i>119</i>&nbsp;
<i>120</i>&nbsp;  /**
<i>121</i>&nbsp;   * Predict all possible lemmas (using a default upper bound).
<i>122</i>&nbsp;   * @param numLemmas the default number of lemmas
<i>123</i>&nbsp;   * @param toks the tokens
<i>124</i>&nbsp;   * @param tags the postags
<i>125</i>&nbsp;   * @return a double array containing all posible lemmas for each token and postag pair
<i>126</i>&nbsp;   */
<i>127</i>&nbsp;  public String[][] predictLemmas(int numLemmas, String[] toks, String[] tags) {
<b class="nc"><i>128</i>&nbsp;    Sequence[] bestSequences = model.bestSequences(numLemmas, toks, new Object[] {tags},</b>
<i>129</i>&nbsp;            contextGenerator, sequenceValidator);
<b class="nc"><i>130</i>&nbsp;    String[][] allLemmas = new String[bestSequences.length][];</b>
<b class="nc"><i>131</i>&nbsp;    for (int i = 0; i &lt; allLemmas.length; i++) {</b>
<b class="nc"><i>132</i>&nbsp;      List&lt;String&gt; ses = bestSequences[i].getOutcomes();</b>
<b class="nc"><i>133</i>&nbsp;      String[] sesArray = ses.toArray(new String[ses.size()]);</b>
<b class="nc"><i>134</i>&nbsp;      allLemmas[i] = decodeLemmas(toks,sesArray);</b>
<i>135</i>&nbsp;    }
<b class="nc"><i>136</i>&nbsp;    return allLemmas;</b>
<i>137</i>&nbsp;  }
<i>138</i>&nbsp;
<i>139</i>&nbsp;  /**
<i>140</i>&nbsp;   * Decodes the lemma from the word and the induced lemma class.
<i>141</i>&nbsp;   * @param toks the array of tokens
<i>142</i>&nbsp;   * @param preds the predicted lemma classes
<i>143</i>&nbsp;   * @return the array of decoded lemmas
<i>144</i>&nbsp;   */
<i>145</i>&nbsp;  public static String[] decodeLemmas(String[] toks, String[] preds) {
<b class="fc"><i>146</i>&nbsp;    List&lt;String&gt; lemmas = new ArrayList&lt;&gt;();</b>
<b class="fc"><i>147</i>&nbsp;    for (int i = 0; i &lt; toks.length; i++) {</b>
<b class="fc"><i>148</i>&nbsp;      String lemma = StringUtil.decodeShortestEditScript(toks[i].toLowerCase(), preds[i]);</b>
<b class="fc"><i>149</i>&nbsp;      if (lemma.length() == 0) {</b>
<b class="nc"><i>150</i>&nbsp;        lemma = &quot;_&quot;;</b>
<i>151</i>&nbsp;      }
<b class="fc"><i>152</i>&nbsp;      lemmas.add(lemma);</b>
<i>153</i>&nbsp;    }
<b class="fc"><i>154</i>&nbsp;    return lemmas.toArray(new String[lemmas.size()]);</b>
<i>155</i>&nbsp;  }
<i>156</i>&nbsp;
<i>157</i>&nbsp;  public static String[] encodeLemmas(String[] toks, String[] lemmas) {
<b class="fc"><i>158</i>&nbsp;    List&lt;String&gt; sesList = new ArrayList&lt;&gt;();</b>
<b class="fc"><i>159</i>&nbsp;    for (int i = 0; i &lt; toks.length; i++) {</b>
<b class="fc"><i>160</i>&nbsp;      String ses = StringUtil.getShortestEditScript(toks[i], lemmas[i]);</b>
<b class="fc"><i>161</i>&nbsp;      if (ses.length() == 0) {</b>
<b class="nc"><i>162</i>&nbsp;        ses = &quot;_&quot;;</b>
<i>163</i>&nbsp;      }
<b class="fc"><i>164</i>&nbsp;      sesList.add(ses);</b>
<i>165</i>&nbsp;    }
<b class="fc"><i>166</i>&nbsp;    return sesList.toArray(new String[sesList.size()]);</b>
<i>167</i>&nbsp;  }
<i>168</i>&nbsp;
<i>169</i>&nbsp;  public Sequence[] topKSequences(String[] sentence, String[] tags) {
<b class="nc"><i>170</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, sentence,</b>
<i>171</i>&nbsp;        new Object[] { tags }, contextGenerator, sequenceValidator);
<i>172</i>&nbsp;  }
<i>173</i>&nbsp;
<i>174</i>&nbsp;  public Sequence[] topKSequences(String[] sentence, String[] tags, double minSequenceScore) {
<b class="nc"><i>175</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, sentence, new Object[] { tags }, minSequenceScore,</b>
<i>176</i>&nbsp;        contextGenerator, sequenceValidator);
<i>177</i>&nbsp;  }
<i>178</i>&nbsp;
<i>179</i>&nbsp;  /**
<i>180</i>&nbsp;   * Populates the specified array with the probabilities of the last decoded sequence.  The
<i>181</i>&nbsp;   * sequence was determined based on the previous call to &lt;code&gt;lemmatize&lt;/code&gt;.  The
<i>182</i>&nbsp;   * specified array should be at least as large as the number of tokens in the
<i>183</i>&nbsp;   * previous call to &lt;code&gt;lemmatize&lt;/code&gt;.
<i>184</i>&nbsp;   *
<i>185</i>&nbsp;   * @param probs An array used to hold the probabilities of the last decoded sequence.
<i>186</i>&nbsp;   */
<i>187</i>&nbsp;  public void probs(double[] probs) {
<b class="nc"><i>188</i>&nbsp;    bestSequence.getProbs(probs);</b>
<b class="nc"><i>189</i>&nbsp;  }</b>
<i>190</i>&nbsp;
<i>191</i>&nbsp;  /**
<i>192</i>&nbsp;   * Returns an array with the probabilities of the last decoded sequence.  The
<i>193</i>&nbsp;   * sequence was determined based on the previous call to &lt;code&gt;chunk&lt;/code&gt;.
<i>194</i>&nbsp;   * @return An array with the same number of probabilities as tokens were sent to &lt;code&gt;chunk&lt;/code&gt;
<i>195</i>&nbsp;   *     when it was last called.
<i>196</i>&nbsp;   */
<i>197</i>&nbsp;  public double[] probs() {
<b class="nc"><i>198</i>&nbsp;    return bestSequence.getProbs();</b>
<i>199</i>&nbsp;  }
<i>200</i>&nbsp;
<i>201</i>&nbsp;  public static LemmatizerModel train(String languageCode,
<i>202</i>&nbsp;      ObjectStream&lt;LemmaSample&gt; samples, TrainingParameters trainParams,
<i>203</i>&nbsp;      LemmatizerFactory posFactory) throws IOException {
<i>204</i>&nbsp;
<b class="fc"><i>205</i>&nbsp;    int beamSize = trainParams.getIntParameter(BeamSearch.BEAM_SIZE_PARAMETER,</b>
<i>206</i>&nbsp;            LemmatizerME.DEFAULT_BEAM_SIZE);
<i>207</i>&nbsp;
<b class="fc"><i>208</i>&nbsp;    LemmatizerContextGenerator contextGenerator = posFactory.getContextGenerator();</b>
<i>209</i>&nbsp;
<b class="fc"><i>210</i>&nbsp;    Map&lt;String, String&gt; manifestInfoEntries = new HashMap&lt;&gt;();</b>
<i>211</i>&nbsp;
<b class="fc"><i>212</i>&nbsp;    TrainerType trainerType = TrainerFactory.getTrainerType(trainParams);</b>
<i>213</i>&nbsp;
<b class="fc"><i>214</i>&nbsp;    MaxentModel lemmatizerModel = null;</b>
<b class="fc"><i>215</i>&nbsp;    SequenceClassificationModel&lt;String&gt; seqLemmatizerModel = null;</b>
<b class="fc"><i>216</i>&nbsp;    if (TrainerType.EVENT_MODEL_TRAINER.equals(trainerType)) {</b>
<b class="fc"><i>217</i>&nbsp;      ObjectStream&lt;Event&gt; es = new LemmaSampleEventStream(samples, contextGenerator);</b>
<i>218</i>&nbsp;
<b class="fc"><i>219</i>&nbsp;      EventTrainer trainer = TrainerFactory.getEventTrainer(trainParams,</b>
<i>220</i>&nbsp;          manifestInfoEntries);
<b class="fc"><i>221</i>&nbsp;      lemmatizerModel = trainer.train(es);</b>
<b class="fc"><i>222</i>&nbsp;    }</b>
<b class="nc"><i>223</i>&nbsp;    else if (TrainerType.EVENT_MODEL_SEQUENCE_TRAINER.equals(trainerType)) {</b>
<b class="nc"><i>224</i>&nbsp;      LemmaSampleSequenceStream ss = new LemmaSampleSequenceStream(samples, contextGenerator);</b>
<b class="nc"><i>225</i>&nbsp;      EventModelSequenceTrainer trainer =</b>
<b class="nc"><i>226</i>&nbsp;          TrainerFactory.getEventModelSequenceTrainer(trainParams, manifestInfoEntries);</b>
<b class="nc"><i>227</i>&nbsp;      lemmatizerModel = trainer.train(ss);</b>
<b class="nc"><i>228</i>&nbsp;    }</b>
<b class="nc"><i>229</i>&nbsp;    else if (TrainerType.SEQUENCE_TRAINER.equals(trainerType)) {</b>
<b class="nc"><i>230</i>&nbsp;      SequenceTrainer trainer = TrainerFactory.getSequenceModelTrainer(</b>
<i>231</i>&nbsp;          trainParams, manifestInfoEntries);
<i>232</i>&nbsp;
<i>233</i>&nbsp;      // TODO: This will probably cause issue, since the feature generator uses the outcomes array
<i>234</i>&nbsp;
<b class="nc"><i>235</i>&nbsp;      LemmaSampleSequenceStream ss = new LemmaSampleSequenceStream(samples, contextGenerator);</b>
<b class="nc"><i>236</i>&nbsp;      seqLemmatizerModel = trainer.train(ss);</b>
<b class="nc"><i>237</i>&nbsp;    }</b>
<i>238</i>&nbsp;    else {
<b class="nc"><i>239</i>&nbsp;      throw new IllegalArgumentException(&quot;Trainer type is not supported: &quot; + trainerType);</b>
<i>240</i>&nbsp;    }
<i>241</i>&nbsp;
<b class="fc"><i>242</i>&nbsp;    if (lemmatizerModel != null) {</b>
<b class="fc"><i>243</i>&nbsp;      return new LemmatizerModel(languageCode, lemmatizerModel, beamSize, manifestInfoEntries, posFactory);</b>
<i>244</i>&nbsp;    }
<i>245</i>&nbsp;    else {
<b class="nc"><i>246</i>&nbsp;      return new LemmatizerModel(languageCode, seqLemmatizerModel, manifestInfoEntries, posFactory);</b>
<i>247</i>&nbsp;    }
<i>248</i>&nbsp;  }
<i>249</i>&nbsp;
<i>250</i>&nbsp;  public Sequence[] topKLemmaClasses(String[] sentence, String[] tags) {
<b class="nc"><i>251</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, sentence,</b>
<i>252</i>&nbsp;        new Object[] { tags }, contextGenerator, sequenceValidator);
<i>253</i>&nbsp;  }
<i>254</i>&nbsp;
<i>255</i>&nbsp;  public Sequence[] topKLemmaClasses(String[] sentence, String[] tags, double minSequenceScore) {
<b class="nc"><i>256</i>&nbsp;    return model.bestSequences(DEFAULT_BEAM_SIZE, sentence, new Object[] { tags }, minSequenceScore,</b>
<i>257</i>&nbsp;        contextGenerator, sequenceValidator);
<i>258</i>&nbsp;  }
<i>259</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2020-05-09 18:47</div>
</div>
</body>
</html>
